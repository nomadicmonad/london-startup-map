{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London Start-up Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code performed for the analysis in <a href=\"https://medium.com/@quantscoop/london-animated-start-up-map-2011-2020-3ae5a709edf9\">this blog post</a>.\n",
    "\n",
    "The end result is a map of London that displays relative start-up formation vs cessation:\n",
    "\n",
    "<img src=\"animation.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pgeocode\n",
    "!pip install plotly-express\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install imageio\n",
    "!pip install visvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pgeocode\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import copy\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import requests\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import imageio\n",
    "import glob\n",
    "import visvis as vv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading London Postcode GEO-code JSON\n",
    "\n",
    "We will download the JSON file for the geographical boundaries of London postcodes from <a href=\"https://github.com/sjwhitworth/london_geojson/blob/master/london_postcodes.json\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "london_geojson_url = \"https://raw.githubusercontent.com/sjwhitworth/london_geojson/master/london_postcodes.json\"\n",
    "urllib.request.urlretrieve(london_geojson_url,\"london_postcodes.json\")\n",
    "with open(\"london_postcodes.json\",\"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Companies House Data\n",
    "\n",
    "We will now scrap the details of London-based companies from the Companies House website.\n",
    "\n",
    "You will need an API key, which you can set-up <a href=\"https://developer.companieshouse.gov.uk/api/docs/\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "api_key = \"api_key\"\n",
    "url = \"https://api.companieshouse.gov.uk/company/\"\n",
    "request_counter =  0\n",
    "attempted_company_codes = []\n",
    "scrape_start = 7500000\n",
    "scrape_stop = 12480000\n",
    "scraping_attempts = int(0) # Change to a larger number e.g 10000\n",
    "current_company_id = 0\n",
    "if (os.path.exists(\"companies_house_data.txt\")):\n",
    "    dataframe = pd.read_table(\"companies_house_data.txt\",delimiter=\"\\t\")\n",
    "else:\n",
    "    dataframe = pd.DataFrame(columns=['number','formed','active_until','postcode'])\n",
    "    dataframe.set_index('number')\n",
    "for counter in range(scraping_attempts):\n",
    "    while (current_company_id in attempted_company_codes):\n",
    "        current_company_id = random.randint(scrape_start,scrape_stop)\n",
    "    attempted_company_codes.append(current_company_id)\n",
    "    str_company_id = str(current_company_id).zfill(8)\n",
    "    request_result = requests.get(url = url + str_company_id, auth = (api_key,\"\"))\n",
    "    request_counter +=1\n",
    "    json_fail = False\n",
    "    json_result = request_result.json()\n",
    "    try:\n",
    "        sys.stdout = io.StringIO()\n",
    "        print(json_result)\n",
    "        sys.stdout = sys.__stdout__\n",
    "    except:\n",
    "        json_fail = True\n",
    "    # Sleep when requests close to rate limit.\n",
    "    if (request_counter > 550):\n",
    "        request_counter = 0\n",
    "        time.sleep(300)\n",
    "        print(\"sleeping for 5 min\")\n",
    "    print(\"Counter: {}\".format(counter))\n",
    "    contains_registered_office = 'registered_office_address' in json_result\n",
    "    is_situated_in_london = contains_registered_office and \\\n",
    "    'locality' in json_result['registered_office_address'] \\\n",
    "    and 'London' in json_result['registered_office_address']['locality']\n",
    "    contains_company_status = 'company_status' in json_result\n",
    "    contains_errors = 'errors' in json_result\n",
    "    contains_postal_code = contains_registered_office and 'postal_code' in json_result['registered_office_address']\n",
    "    is_error_free = json_fail == False and contains_errors == False\n",
    "    if (is_error_free and contains_postal_code and is_situated_in_london and contains_company_status):\n",
    "        cur_dict = {}\n",
    "        cur_dict['number'] = json_result['company_number']\n",
    "        cur_dict['formed'] = json_result['date_of_creation']\n",
    "        cur_dict['active_until'] = json_result['date_of_cessation'] if 'date_of_cessation' in json_result else \"2020-12-01\"\n",
    "        cur_dict['postcode'] = cessation,json_result['registered_office_address']['postal_code']\n",
    "        dataframe.append(cur_dict,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the set of existing postcodes in the JSON and apply reformatting for further down the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postcodes_extant = set()\n",
    "for counter in range(len(data['features'])):\n",
    "    data['features'][counter]['id'] = data['features'][counter]['properties']['Name']\n",
    "    postcodes_extant.add(data['features'][counter]['properties']['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to compare the Companies House company postcode data vs. the London postcodes, we will use this utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_closest_postcode(postcode, postcodes_list):\n",
    "    if (\" \" in postcode and postcode.split()[0] in postcodes_list):\n",
    "        return postcode.split()[0]\n",
    "    postcode = ''.join(postcode.split())\n",
    "    longest = \"\"\n",
    "    for pc in postcodes_list:\n",
    "        result = postcode.find(pc)\n",
    "        if (result == 0 and len(pc) > len(longest)):\n",
    "            longest = pc\n",
    "    return longest\n",
    "\n",
    "postcodes_list = list(postcodes_extant)\n",
    "dataframe['postcode'] = [get_closest_postcode(val.upper(), postcodes_list) for val in dataframe['postcode'].values.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets transform the company creation vs. cessation dates to python datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['dt1'] = [datetime.date(int(val.split(\"-\")[0]), int(val.split(\"-\")[1]),1) for val in dataframe['formed'].values.tolist()]\n",
    "dataframe['dt2'] = [datetime.date(int(val.split(\"-\")[0]), int(val.split(\"-\")[1]),1) for val in dataframe['active_until'].values.tolist()]\n",
    "\n",
    "earliest = min(dataframe['dt1'].tolist())\n",
    "latest = max(dataframe['dt1'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another utility function for getting the time-difference between months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_months_dif(d1,d2):\n",
    "    return d1.month - d2.month + 12*(d1.year-d2.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create a dictionary that maps postcodes to how many companies were\n",
    "active in a given period (represented as a numpy array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_months = get_months_dif(latest,earliest)\n",
    "postcode_dict = collections.defaultdict(lambda:np.zeros((total_months+1)))\n",
    "total = np.zeros((total_months+1))\n",
    "total2 = np.zeros((total_months+1))\n",
    "for index,row in dataframe.iterrows():\n",
    "    matrix = np.zeros((total_months+1))\n",
    "    start_months = get_months_dif(row['dt1'],earliest)\n",
    "    end_months = get_months_dif(min(row['dt2'],latest),earliest)\n",
    "    matrix[start_months:end_months] = 1.0\n",
    "    postcode_dict[row['postcode']] += matrix\n",
    "    test = np.zeros((total_months+1))\n",
    "    test2 = np.zeros((total_months+1))\n",
    "    test[end_months] = 1\n",
    "    test2[start_months] = 1\n",
    "    total += matrix\n",
    "    total2 += test2\n",
    "\n",
    "postcode_vals = postcode_dict.values()\n",
    "\n",
    "max_val = 0\n",
    "#We will take the square root of the number of active companies for visual purposes\n",
    "for i in postcode_vals:\n",
    "    max_val = np.power(max(max_val,np.max(i,axis=0)),0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a mapping of postcodes to transformed net-active company values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotting_values = [pd.DataFrame.from_dict({'id': list(postcode_dict.keys()), 'val': [float(np.power(val[index],0.5)) for val in list(postcode_dict.values())]}) for index in range(total_months)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we will plot each month of the start-up map using the plotly express choropleth map,\n",
    "and save them as PNGs, which are then combined with imageio into an animated .gif image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viridis = cm.get_cmap('viridis', int(max_val)+1)\n",
    "viridis.colors\n",
    "\n",
    "def get_col(viridis_val):\n",
    "    return 'rgb({},{},{})'.format(int(viridis_val[0]*255),int(viridis_val[1]*255),int(viridis_val[2]*255))\n",
    "\n",
    "colorscale = {}\n",
    "colorscale2 = ((0.0,get_col(viridis.colors[0])),)\n",
    "\n",
    "for index in range(1,int(max_val)+1):\n",
    "    colorscale[float(index)] = get_col(viridis.colors[index])\n",
    "    colorscale2 += ((float(index),get_col(viridis.colors[index])),)\n",
    "\n",
    "for index in range(total_months):\n",
    "    day = earliest + relativedelta(months=index)\n",
    "    fig = px.choropleth_mapbox(plotting_values[index], geojson=data, locations='id', color='val',\n",
    "                               color_continuous_scale =\"RdYlGn\",\n",
    "                               range_color=(0, float(max_val)),\n",
    "                               mapbox_style='carto-positron',\n",
    "                               zoom=10, center = {\"lat\": 51.5073, \"lon\": -0.1277},\n",
    "                               opacity=0.1,\n",
    "                               labels={'val':'(sqrt) Net Active'}\n",
    "                              )\n",
    "    fig.update_layout(title=\"   London: (sqrt of) Active Companies per Month, {}-{}\".format(day.year,day.month), title_font_size=24)\n",
    "    fig.layout.coloraxis.autocolorscale= False\n",
    "    fig.layout.coloraxis.cauto= False\n",
    "    fig.layout.coloraxis.cmin= 0.0\n",
    "    fig.layout.coloraxis.cmax= float(max_val)\n",
    "    fig.write_image(\"./images_output/image_{}_{}_{}.png\".format(day.year,day.month//10,day.month%10))\n",
    "    \n",
    "images = []\n",
    "imageio.plugins.freeimage.download()\n",
    "for filename in sorted(glob.glob(\"./images_output/*.png\")):\n",
    "    images.append(imageio.imread(filename))\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('animation.gif', images, 'GIF-FI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
